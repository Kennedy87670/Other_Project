{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "food_vision101.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOe2EjIRy8FeysfD5JcEd1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kennedy87670/Other_Project/blob/main/food_vision101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Milestone Project 1:* Food Vision Big\n",
        "\n"
      ],
      "metadata": {
        "id": "b54_NbjXjafp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check GPU\n",
        "\n",
        "Google colab offers free GPUs (thank you google), however, not all of the are compatiable with mixed precision training.\n",
        "\n",
        "Google Colab offers:\n",
        "* K80 (not compactable)\n",
        "* P100 (not compactable)\n",
        "Tesla T4 (compactable)\n",
        "\n",
        "knowing this in order to use mixed precision training we need access to a tesla T4 (from within Google colab) or if we are using our own hardware, our GPU needs a score of 7.0+ \n"
      ],
      "metadata": {
        "id": "cviheJNtlAWz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4616Ve2M-eA",
        "outputId": "b309c3f7-926f-4aca-80b5-fa877605314f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-215dba73-78a2-1c55-6e9a-b10f1b709df2)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get helper functions\n",
        "\n",
        "In the past modules, we've created a bunch of helper functions to do small tasks required for our notebooks.\n",
        "\n",
        "Rather than rewrite all of these, we can import a script and oad them in from there"
      ],
      "metadata": {
        "id": "E3CRbrKWmxRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download  helper function script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZHFYwrQmUaX",
        "outputId": "67800315-2f8d-4b1b-9841-70d3bf275f51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-01 22:53:56--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-01 22:53:56 (70.6 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import series of helper function \n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "QubLWCUnnadz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use tensorflow dataset to download in Tensorflow\n",
        "https://www.tensorflow.org/datasets"
      ],
      "metadata": {
        "id": "crWYEmJZns_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get Tensorflow Dataset\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "UdVMhJVxnpCT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all avilable datasets\n",
        "datasets_list = tfds.list_builders() # get all available datasets in TFDS\n",
        "print(\"food101\" in datasets_list) # is our target dataset in the list of TFDS dataset?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpGeFykTpNr-",
        "outputId": "3526c6ca-e177-4ec7-d125-88e0fa75909d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# exploring the food101 data from tensorflow Datasets\n",
        "\n",
        "To become one with our data, we want to find:\n",
        "* Class names\n",
        "* The shape of our input data (image tensor)\n",
        "* The datatype of our input data\n",
        "* what the labels look like (e.g are they one-hot encoded or are they label encoded)\n",
        "* Do the labels match up with the class name?"
      ],
      "metadata": {
        "id": "bEKpI_d80kY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load in the data (takes 5-6 minutes in google colab)\n",
        "(train_data, test_data), ds_info= tfds.load(name=\"food101\",\n",
        "                                            split=[\"train\", \"validation\"],\n",
        "                                            shuffle_files=True,\n",
        "                                            as_supervised=True, # data gets returned in tuple format (data, label)\n",
        "                                            with_info=True)"
      ],
      "metadata": {
        "id": "6QSW6_M1p0J0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features of food101 from TFDS\n",
        "ds_info.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9yNafEnuiA2",
        "outputId": "fae76511-d3fa-4648-9832-484bf470df49"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeaturesDict({\n",
              "    'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
              "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=101),\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the class names\n",
        "class_names = ds_info.features['label'].names\n",
        "class_names[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH-B4sibuxjP",
        "outputId": "0a0a84ee-62f4-41aa-c63d-36ef18de80db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple_pie',\n",
              " 'baby_back_ribs',\n",
              " 'baklava',\n",
              " 'beef_carpaccio',\n",
              " 'beef_tartare',\n",
              " 'beet_salad',\n",
              " 'beignets',\n",
              " 'bibimbap',\n",
              " 'bread_pudding',\n",
              " 'breakfast_burrito']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take one sample of train data"
      ],
      "metadata": {
        "id": "qBWsnrdByPwG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}